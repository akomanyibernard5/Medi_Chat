{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgGX1jJDxDNO",
        "outputId": "d146ef36-b769-4ba6-bd90-7dbbe4cc7c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h8etCi3Rlo0",
        "outputId": "2dcb8cda-f3c5-4149-d395-651ce4f08d62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Backend_old\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Backend_old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXmPUs_HRoAz"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Backend_old')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Symptom Classifier model"
      ],
      "metadata": {
        "id": "jHGphrS_j025"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcPk_rl_R1Us",
        "outputId": "3e860b52-3241-486b-eed1-a10783e8d72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing custom modules"
      ],
      "metadata": {
        "id": "L2tdbZ7pjVkh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgF7h_F_R3s0"
      },
      "outputs": [],
      "source": [
        "from nltk_utils import tokenize, stem, build_vocab, sentence_to_indices\n",
        "from nnet import NeuralNet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "n_BoLmzbh3Lw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR1Na9NWR6Tm"
      },
      "outputs": [],
      "source": [
        "with open(\"multi_label_dataset.json\", \"r\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting all tags"
      ],
      "metadata": {
        "id": "o5AhYR_LiLmE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzcRChyESb45"
      },
      "outputs": [],
      "source": [
        "all_tags = sorted(set(tag for item in data for tag in item['tags']))\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(all_tags)}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building vocab\n"
      ],
      "metadata": {
        "id": "Cueay_jgiP7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_sentences = [item[\"sentence\"] for item in data]\n",
        "vocab, word2idx = build_vocab(all_sentences)"
      ],
      "metadata": {
        "id": "U6r33mLziPI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Hyperparameters\n"
      ],
      "metadata": {
        "id": "JIImFIygiYO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 10\n",
        "embed_size = 64\n",
        "hidden_size = 32\n",
        "output_size = len(all_tags)\n",
        "vocab_size = len(word2idx)\n",
        "batch_size = 8\n",
        "num_epochs = 1000\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "rirjhC0kiVxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing training data"
      ],
      "metadata": {
        "id": "58bDOH6Oioe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = [], []\n",
        "\n",
        "for item in data:\n",
        "    indices = sentence_to_indices(item[\"sentence\"], word2idx, max_len)\n",
        "    label_vector = [0] * output_size\n",
        "    for tag in item[\"tags\"]:\n",
        "        label_vector[tag2idx[tag]] = 1\n",
        "    X_train.append(indices)\n",
        "    y_train.append(label_vector)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "class MultiLabelDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "dataset = MultiLabelDataset()\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAtos__hideh",
        "outputId": "5e3952b7-5d31-45d1-c97d-d6ce521d58ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-d97cb61291bb>:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  X_train = torch.tensor(X_train, dtype=torch.long)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model and training setup"
      ],
      "metadata": {
        "id": "ZVbHP7W9izqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(vocab_size, embed_size, hidden_size, output_size, max_len)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "BpLjkZWci3eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training multi-label model...\")\n",
        "for epoch in range(num_epochs):\n",
        "    for words, labels in train_loader:\n",
        "        outputs = model(words)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"✅ Training complete.\")"
      ],
      "metadata": {
        "id": "T6YafVgci860"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the model and metadata"
      ],
      "metadata": {
        "id": "DrFeGR6hjA5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": max_len,\n",
        "    \"hidden_size\": hidden_size,\n",
        "    \"output_size\": output_size,\n",
        "    \"vocab_size\": vocab_size,\n",
        "    \"tags\": all_tags,\n",
        "    \"word2idx\": word2idx\n",
        "}\n",
        "\n",
        "torch.save(model_data, \"models/multi_label_model.pth\")\n",
        "with open(\"models/multi_word2idx.pkl\", \"wb\") as f:\n",
        "    pickle.dump(word2idx, f)\n",
        "\n",
        "print(\"✅ Multi-label model and vocab saved.\")"
      ],
      "metadata": {
        "id": "TddMk3IjjAS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building the Disease Classifier Model"
      ],
      "metadata": {
        "id": "YElRLoIwkZF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "model = NeuralNet(vocab_size, embed_size, hidden_size, output_size, max_len)\n",
        "criterion = nn.BCEWithLogitsLoss()  # multi-label loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "BcYunBB1ivPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ],
      "metadata": {
        "id": "OOA0wKNtkd1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "vcNuAOsEkfIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and inspect the dataset\n",
        "df = pd.read_csv(\"Training.csv\")\n",
        "print(\"First 5 rows of data:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOWONlRzkhVu",
        "outputId": "849e69e8-5590-4d7f-ab45-aa132ba6d001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of data:\n",
            "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
            "0        1          1                     1                    0          0   \n",
            "1        0          1                     1                    0          0   \n",
            "2        1          0                     1                    0          0   \n",
            "3        1          1                     0                    0          0   \n",
            "4        1          1                     1                    0          0   \n",
            "\n",
            "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  scurring  \\\n",
            "0       0           0             0        0                 0  ...         0   \n",
            "1       0           0             0        0                 0  ...         0   \n",
            "2       0           0             0        0                 0  ...         0   \n",
            "3       0           0             0        0                 0  ...         0   \n",
            "4       0           0             0        0                 0  ...         0   \n",
            "\n",
            "   skin_peeling  silver_like_dusting  small_dents_in_nails  \\\n",
            "0             0                    0                     0   \n",
            "1             0                    0                     0   \n",
            "2             0                    0                     0   \n",
            "3             0                    0                     0   \n",
            "4             0                    0                     0   \n",
            "\n",
            "   inflammatory_nails  blister  red_sore_around_nose  yellow_crust_ooze  \\\n",
            "0                   0        0                     0                  0   \n",
            "1                   0        0                     0                  0   \n",
            "2                   0        0                     0                  0   \n",
            "3                   0        0                     0                  0   \n",
            "4                   0        0                     0                  0   \n",
            "\n",
            "          prognosis  Unnamed: 133  \n",
            "0  Fungal infection           NaN  \n",
            "1  Fungal infection           NaN  \n",
            "2  Fungal infection           NaN  \n",
            "3  Fungal infection           NaN  \n",
            "4  Fungal infection           NaN  \n",
            "\n",
            "[5 rows x 134 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary unnamed columns\n",
        "df.drop(columns=[col for col in df.columns if 'Unnamed' in col], inplace=True)"
      ],
      "metadata": {
        "id": "KP1rVqaik7jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea0sAbfAk-yZ",
        "outputId": "392a2116-c19e-4978-ef2b-43754c4b2c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "itching                 0\n",
            "skin_rash               0\n",
            "nodal_skin_eruptions    0\n",
            "continuous_sneezing     0\n",
            "shivering               0\n",
            "                       ..\n",
            "inflammatory_nails      0\n",
            "blister                 0\n",
            "red_sore_around_nose    0\n",
            "yellow_crust_ooze       0\n",
            "prognosis               0\n",
            "Length: 133, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (symptoms) and labels (disease predictions)\n",
        "X = df.drop(\"prognosis\", axis=1).astype(int)  # Input features\n",
        "y = df[\"prognosis\"]  # Output labels"
      ],
      "metadata": {
        "id": "bD1zYx4zlA2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding disease names into numerical values\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)"
      ],
      "metadata": {
        "id": "_uonqB8MlC2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving label encoder for later use in the backend\n",
        "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
        "    pickle.dump(le, f)"
      ],
      "metadata": {
        "id": "T0ynCShelKoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving list of symptoms for use in backend\n",
        "with open(\"list_of_symptoms.pickle\", \"wb\") as f:\n",
        "    pickle.dump(X.columns.tolist(), f)"
      ],
      "metadata": {
        "id": "ZVZsFN0xlXFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)"
      ],
      "metadata": {
        "id": "vKff7Ii5lbm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform cross-validation and find best parameters\n",
        "def cross_validation(X_train, y_train, X_test, y_test, model_name, parameter_range=15):\n",
        "    train_errors, test_errors = [], []\n",
        "    parameters = np.arange(1, parameter_range + 1)\n",
        "\n",
        "    for parameter in parameters:\n",
        "        if model_name == 'knn':\n",
        "            model = KNeighborsClassifier(n_neighbors=parameter)\n",
        "        elif model_name == 'logreg':\n",
        "            model = LogisticRegression(solver='liblinear', C=1/(parameter*10))\n",
        "        elif model_name == 'dctree':\n",
        "            model = DecisionTreeClassifier(splitter='random', max_depth=parameter)\n",
        "        elif model_name == 'svm':\n",
        "            model = SVC(C=1/(parameter*5))\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        train_errors.append(1 - model.score(X_train, y_train))\n",
        "        test_errors.append(1 - model.score(X_test, y_test))\n",
        "\n",
        "    # Returning the best parameter\n",
        "    if model_name == 'logreg':\n",
        "        best_param = 1/(parameters[np.argmin(test_errors)]*10)\n",
        "    elif model_name == 'svm':\n",
        "        best_param = 1/(parameters[np.argmin(test_errors)]*5)\n",
        "    else:\n",
        "        best_param = parameters[np.argmin(test_errors)]\n",
        "\n",
        "    return parameters, best_param, train_errors, test_errors"
      ],
      "metadata": {
        "id": "aZTnrih1lhu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding best hyperparameters for each model\n",
        "best_params = {}\n",
        "for model_name in ['knn', 'dctree', 'logreg', 'svm']:\n",
        "    print(f\"🔍 Tuning {model_name}...\")\n",
        "    _, best, _, _ = cross_validation(X_train, y_train, X_test, y_test, model_name)\n",
        "    best_params[model_name] = best\n",
        "    print(f\"✅ Best {model_name} parameter: {best}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meihcoqyll1_",
        "outputId": "f12de655-8aa3-4b2b-ee87-9a0e087dafa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Tuning knn...\n",
            "✅ Best knn parameter: 1\n",
            "\n",
            "🔍 Tuning dctree...\n",
            "✅ Best dctree parameter: 15\n",
            "\n",
            "🔍 Tuning logreg...\n",
            "✅ Best logreg parameter: 0.1\n",
            "\n",
            "🔍 Tuning svm...\n",
            "✅ Best svm parameter: 0.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the ensemble using stacking with the best models\n",
        "base_models = [\n",
        "    ('lr', LogisticRegression(solver='liblinear', C=best_params['logreg'])),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=best_params['knn'])),\n",
        "    ('dctree', DecisionTreeClassifier(splitter='random', max_depth=best_params['dctree'])),\n",
        "    ('svm', SVC(C=best_params['svm'], probability=True))\n",
        "]"
      ],
      "metadata": {
        "id": "k04ryIzHlo1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final estimator is Logistic Regression\n",
        "ensemble = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(), cv=5)"
      ],
      "metadata": {
        "id": "x3ycKPUbl-hY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using cross-validation to evaluate ensemble performance\n",
        "cv = RepeatedStratifiedKFold(n_repeats=3, random_state=1)\n",
        "score = cross_val_score(ensemble, X, y_encoded, scoring='accuracy', cv=cv, n_jobs=-1)"
      ],
      "metadata": {
        "id": "iILwqvzMl_dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the ensemble on the full dataset and saving it\n",
        "ensemble.fit(X, y_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0dYoqqgmB21",
        "outputId": "ff1edad2-9a24-4c4b-b094-0f2b95ffd0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Final Ensemble Accuracy: 1.0000 ± 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "individual_models = ensemble.named_estimators_\n",
        "\n",
        "individual_models = ensemble.named_estimators_\n",
        "\n",
        "for model_name, model in individual_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy of {model_name}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB-wp9rnx2oj",
        "outputId": "6c6a825c-dd3c-4439-e473-0214b7df7d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of lr: 1.0000\n",
            "Accuracy of knn: 1.0000\n",
            "Accuracy of dctree: 0.4339\n",
            "Accuracy of svm: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fitted_model_stacked_final.pkl\", \"wb\") as f:\n",
        "    pickle.dump(ensemble, f)\n",
        "\n",
        "print(f\"\\n📊 Final Ensemble Accuracy: {np.mean(score):.4f} ± {np.std(score):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9W7xXI2ymfn",
        "outputId": "14f0ed6e-a8a7-415e-b0cb-3ff59ac1816a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Final Ensemble Accuracy: 1.0000 ± 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hFZDjK3Yy1pL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}